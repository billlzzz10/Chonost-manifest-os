# ğŸ“Š AI Agent Multi-Action Dataset Generator

à¸£à¸°à¸šà¸šà¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¸”à¸²à¸•à¹‰à¸²à¹€à¸‹à¹‡à¸•à¸ˆà¸²à¸ log à¹à¸¥à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¹ˆà¸²à¸‡à¹† à¹ƒà¸™à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„ Chonost

## ğŸ¯ à¸§à¸±à¸•à¸–à¸¸à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œ

à¸£à¸°à¸šà¸šà¸™à¸µà¹‰à¸–à¸¹à¸à¸­à¸­à¸à¹à¸šà¸šà¸¡à¸²à¹€à¸à¸·à¹ˆà¸­à¹à¸›à¸¥à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ log à¸—à¸µà¹ˆà¸”à¸¹à¸§à¸¸à¹ˆà¸™à¸§à¸²à¸¢à¹ƒà¸«à¹‰à¸à¸¥à¸²à¸¢à¹€à¸›à¹‡à¸™ **à¸—à¸£à¸±à¸à¸¢à¹Œà¸ªà¸´à¸™à¸”à¸´à¸ˆà¸´à¸—à¸±à¸¥ (Digital Asset)** à¸—à¸µà¹ˆà¸ˆà¸°à¸—à¸³à¹ƒà¸«à¹‰ AI Agent à¸‚à¸­à¸‡ Chonost ** à¸‰à¸¥à¸²à¸”à¸‚à¸¶à¹‰à¸™à¹ƒà¸™à¸šà¸£à¸´à¸šà¸—à¸‚à¸­à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¹‚à¸”à¸¢à¹€à¸‰à¸à¸²à¸°** ## ğŸ“‹ à¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¸­à¸‡à¸”à¸²à¸•à¹‰à¸²à¹€à¸‹à¹‡à¸•à¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡

### 1. ** Instruction Fine-Tuning (IFT) Dataset** - ** à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢:** à¸ªà¸­à¸™à¹‚à¸¡à¹€à¸”à¸¥ AI à¹ƒà¸«à¹‰ "à¸„à¸´à¸”à¹à¸¥à¸°à¸—à¸³" à¹€à¸«à¸¡à¸·à¸­à¸™à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢à¸à¸±à¸’à¸™à¸²à¹ƒà¸™à¸­à¸¸à¸”à¸¡à¸„à¸•à¸´
- ** à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡:** `(Instruction, Context, Response)` - ** à¹„à¸Ÿà¸¥à¹Œ:** ` datasets/instruction_fine_tuning/instruction_fine_tuning_dataset.jsonl` ### 2. ** RAG Knowledge Base Dataset** - ** à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢:** à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸¥à¸±à¸‡à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸²à¹à¸¥à¸°à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡
- ** à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡:** Chunks à¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡ + Metadata
- ** à¹„à¸Ÿà¸¥à¹Œ:** ` datasets/rag_knowledge_base/rag_knowledge_base.json` ### 3. ** Forecasting & Prediction Dataset** - ** à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢:** à¸à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥à¹ƒà¸«à¹‰à¸„à¸²à¸”à¸à¸²à¸£à¸“à¹Œà¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¹à¸¥à¸°à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ
- ** à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡:** ` (Previous State, Action, New State, Outcome)` - ** à¹„à¸Ÿà¸¥à¹Œ:** ` datasets/forecasting_prediction/forecasting_dataset.json` ## ğŸš€ à¸à¸²à¸£à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¹ƒà¸Šà¹‰à¸‡à¸²à¸™

### à¸à¸²à¸£à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡

```
# à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ dependencies
pip install -r requirements_dataset.txt

# à¸«à¸£à¸·à¸­à¹ƒà¸Šà¹‰ Makefile
make setup
```

### à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸à¸·à¹‰à¸™à¸à¸²à¸™

```
# 1. à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ log à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡
make create-example-log

# 2. à¸ªà¸£à¹‰à¸²à¸‡à¸”à¸²à¸•à¹‰à¸²à¹€à¸‹à¹‡à¸•à¸ˆà¸²à¸à¹„à¸Ÿà¸¥à¹Œà¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡
make generate-example

# 3. à¸”à¸¹à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ
make list-datasets
make show-stats
```

### à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸à¸±à¸šà¹„à¸Ÿà¸¥à¹Œ log à¸‚à¸­à¸‡à¸„à¸¸à¸“

```
# à¸ªà¸£à¹‰à¸²à¸‡à¸”à¸²à¸•à¹‰à¸²à¹€à¸‹à¹‡à¸•à¸ˆà¸²à¸à¹„à¸Ÿà¸¥à¹Œ log à¸‚à¸­à¸‡à¸„à¸¸à¸“
make generate-datasets LOG_FILE=path/to/your/log.txt

# à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡
make generate-datasets LOG_FILE=logs/conversation_2024_12_19.txt
```

## ğŸ“ à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ

```
datasets/
â”œâ”€â”€ instruction_fine_tuning/
â”‚   â””â”€â”€ instruction_fine_tuning_dataset.jsonl
â”œâ”€â”€ rag_knowledge_base/
â”‚   â””â”€â”€ rag_knowledge_base.json
â”œâ”€â”€ forecasting_prediction/
â”‚   â””â”€â”€ forecasting_dataset.json
â””â”€â”€ dataset_generation_summary.json
```

## ğŸ”§ à¸„à¸³à¸ªà¸±à¹ˆà¸‡ Makefile à¸—à¸µà¹ˆà¸¡à¸µà¸›à¸£à¸°à¹‚à¸¢à¸Šà¸™à¹Œ

```
# à¹à¸ªà¸”à¸‡à¸„à¸§à¸²à¸¡à¸Šà¹ˆà¸§à¸¢à¹€à¸«à¸¥à¸·à¸­
make help

# à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡à¸£à¸°à¸šà¸š
make setup

# à¸ªà¸£à¹‰à¸²à¸‡à¸”à¸²à¸•à¹‰à¸²à¹€à¸‹à¹‡à¸•
make generate-datasets LOG_FILE=your_log.txt

# à¸—à¸”à¸ªà¸­à¸šà¸£à¸°à¸šà¸š
make test

# à¸¥à¸šà¹„à¸Ÿà¸¥à¹Œà¸”à¸²à¸•à¹‰à¸²à¹€à¸‹à¹‡à¸•
make clean

# à¹à¸ªà¸”à¸‡à¸£à¸²à¸¢à¸à¸²à¸£à¸”à¸²à¸•à¹‰à¸²à¹€à¸‹à¹‡à¸•
make list-datasets

# à¹à¸ªà¸”à¸‡à¸ªà¸–à¸´à¸•à¸´
make show-stats

# à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸­à¸¢à¹ˆà¸²à¸‡à¸£à¸§à¸”à¹€à¸£à¹‡à¸§
make quick-start
```

## ğŸ“ à¸£à¸¹à¸›à¹à¸šà¸šà¹„à¸Ÿà¸¥à¹Œ Log à¸—à¸µà¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š

à¸£à¸°à¸šà¸šà¸£à¸­à¸‡à¸£à¸±à¸šà¹„à¸Ÿà¸¥à¹Œ log à¸—à¸µà¹ˆà¸¡à¸µà¸£à¸¹à¸›à¹à¸šà¸šà¸”à¸±à¸‡à¸™à¸µà¹‰:

```
User: à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸«à¸£à¸·à¸­à¸„à¸³à¸–à¸²à¸¡à¸‚à¸­à¸‡à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰
- --
AI: à¸„à¸³à¸•à¸­à¸šà¸«à¸£à¸·à¸­à¸à¸²à¸£à¸•à¸­à¸šà¸ªà¸™à¸­à¸‡à¸‚à¸­à¸‡ AI
- --
System: à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸£à¸°à¸šà¸šà¸«à¸£à¸·à¸­ error
- --
User: à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸•à¹ˆà¸­à¹„à¸›
- --
AI: à¸„à¸³à¸•à¸­à¸šà¸•à¹ˆà¸­à¹„à¸›
```

### à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ log

```
User: à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹à¸¥à¸°à¸ªà¸£à¹‰à¸²à¸‡à¸”à¸²à¸•à¹‰à¸²à¹€à¸‹à¹‡à¸•à¸•à¸²à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸™à¸µà¹‰
- --
AI: à¸‰à¸±à¸™à¸ˆà¸°à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹à¸¥à¸°à¸ªà¸£à¹‰à¸²à¸‡à¸”à¸²à¸•à¹‰à¸²à¹€à¸‹à¹‡à¸•à¸•à¸²à¸¡à¸—à¸µà¹ˆà¸„à¸¸à¸“à¸•à¹‰à¸­à¸‡à¸à¸²à¸£
- --
User: à¹à¸¥à¹‰à¸§à¸à¹‡à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰à¸­à¸­à¸¥à¸²à¸¡à¸²à¸¥à¸´à¸ªà¹€à¸Šà¹‰à¸„à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡à¸”à¸¹à¸§à¹ˆà¸²à¸ˆà¸°à¹€à¸­à¸²à¹€à¸­à¹€à¸ˆà¸™à¸•à¸±à¸§à¹„à¸«à¸™à¹„à¸›à¸—à¸³à¸­à¸°à¹„à¸£à¸šà¹‰à¸²à¸‡
- --
AI: à¸‰à¸±à¸™à¸ˆà¸°à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Ollama à¹à¸¥à¸°à¹à¸™à¸°à¸™à¸³à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ AI agents
- --
System: Error occurred: Connection timeout
- --
AI: à¸‰à¸±à¸™à¸ˆà¸°à¹à¸à¹‰à¹„à¸‚à¸›à¸±à¸à¸«à¸²à¸à¸²à¸£à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­
```

## ğŸ” à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸‚à¸­à¸‡à¸£à¸°à¸šà¸š

### 1. à¸à¸²à¸£à¸ªà¸à¸±à¸”à¹à¸¥à¸°à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
- à¹à¸¢à¸à¸šà¸¥à¹‡à¸­à¸à¸•à¸²à¸¡ ` ---`
- à¸£à¸°à¸šà¸¸à¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸°à¸šà¸¥à¹‡à¸­à¸ (User, AI, System)
- à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡ (à¸¥à¸š request ID, à¹à¸à¹‰à¹„à¸‚à¸­à¸±à¸à¸‚à¸£à¸°à¸œà¸´à¸”à¹€à¸à¸µà¹‰à¸¢à¸™)

### 2. à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¸° Annotation
- à¸ªà¸£à¹‰à¸²à¸‡ ` DatasetEntry` objects
- à¸ªà¸à¸±à¸” metadata (file path, language, etc.)
- à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ entries

### 3. à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¸”à¸²à¸•à¹‰à¸²à¹€à¸‹à¹‡à¸•à¹à¸•à¹ˆà¸¥à¸°à¸›à¸£à¸°à¹€à¸ à¸—
- ** IFT:** à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸¹à¹ˆ (Instruction, Response)
- ** RAG:** à¹à¸šà¹ˆà¸‡à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¹€à¸›à¹‡à¸™ chunks
- ** Forecast:** à¸ªà¸£à¹‰à¸²à¸‡à¸¥à¸³à¸”à¸±à¸š (State, Action, Outcome)

## ğŸ“Š à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ

### IFT Dataset (JSONL format)

```
{
  "instruction": "à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹à¸¥à¸°à¸ªà¸£à¹‰à¸²à¸‡à¸”à¸²à¸•à¹‰à¸²à¹€à¸‹à¹‡à¸•à¸•à¸²à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸™à¸µà¹‰",
  "context": "System: Error occurred: Connection timeout",
  "response": "à¸‰à¸±à¸™à¸ˆà¸°à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹à¸¥à¸°à¸ªà¸£à¹‰à¸²à¸‡à¸”à¸²à¸•à¹‰à¸²à¹€à¸‹à¹‡à¸•à¸•à¸²à¸¡à¸—à¸µà¹ˆà¸„à¸¸à¸“à¸•à¹‰à¸­à¸‡à¸à¸²à¸£",
  "metadata": {
    "source_entry": "log_entry_001",
    "response_entry": "log_entry_002",
    "type": "Instruction"
  }
}
```

### RAG Dataset (JSON format)

```
{
  "dataset_name": "rag_knowledge_base",
  "description": "Knowledge base for RAG system",
  "version": "1.0.0",
  "created_date": "2024-12-19T10:30:00Z",
  "chunks": [
    {
      "chunk_id": "log_entry_001_chunk_0",
      "content": "User: à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹à¸¥à¸°à¸ªà¸£à¹‰à¸²à¸‡à¸”à¸²à¸•à¹‰à¸²à¹€à¸‹à¹‡à¸•...",
      "metadata": {
        "source_entry": "log_entry_001",
        "chunk_index": 0,
        "file_path": "",
        "language": "",
        "type": "Instruction"
      }
    }
  ]
}
```

## ğŸ›  ï¸ à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¹à¸¥à¸°à¸‚à¸¢à¸²à¸¢

### à¸à¸²à¸£à¹€à¸à¸´à¹ˆà¸¡à¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸¡à¹ˆ

à¹à¸à¹‰à¹„à¸‚à¹„à¸Ÿà¸¥à¹Œ ` src/dataset_generator.py` :

```
def _classify_block(self, block: str) -> str:
    # à¹€à¸à¸´à¹ˆà¸¡à¹€à¸‡à¸·à¹ˆà¸­à¸™à¹„à¸‚à¹ƒà¸«à¸¡à¹ˆ
    if 'your_keyword' in block.lower():
        return 'YourNewType'
    # ... existing code
```

### à¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸à¸²à¸£ chunking

```
def _create_chunks(self, content: str, max_chunk_size: int = 1000) -> List[str]:
    # à¸›à¸£à¸±à¸šà¸‚à¸™à¸²à¸” chunk à¸«à¸£à¸·à¸­à¸§à¸´à¸˜à¸µà¸à¸²à¸£à¹à¸šà¹ˆà¸‡
    # ... existing code
```

## ğŸ” à¸à¸²à¸£à¹à¸à¹‰à¹„à¸‚à¸›à¸±à¸à¸«à¸²

### à¸›à¸±à¸à¸«à¸²à¸—à¸µà¹ˆà¸à¸šà¸šà¹ˆà¸­à¸¢

1. ** Import Error:** ```bash
   # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¹„à¸Ÿà¸¥à¹Œ dataset_generator.py à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™ src/
   ls src/dataset_generator.py
   ```

2. ** Log file not found:** ```bash
   # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š path à¸‚à¸­à¸‡à¹„à¸Ÿà¸¥à¹Œ log
   ls -la your_log_file.txt
   ```

3. ** No datasets generated:** ```bash
   # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸£à¸¹à¸›à¹à¸šà¸šà¸‚à¸­à¸‡à¹„à¸Ÿà¸¥à¹Œ log
   head -10 your_log_file.txt
   ```

### à¸à¸²à¸£ Debug

```
# à¸£à¸±à¸™à¹ƒà¸™à¹‚à¸«à¸¡à¸” verbose
python -v scripts/generate_datasets.py your_log.txt

# à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š logs
tail -f logs/dataset_generation.log
```

## ğŸ“ˆ à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡

### à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡ Embeddings

```
# à¹€à¸à¸´à¹ˆà¸¡à¹ƒà¸™ requirements_dataset.txt
# sentence-transformers>=2.2.0

# à¹ƒà¸Šà¹‰à¹ƒà¸™ dataset_generator.py
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('all-MiniLM-L6-v2')
embeddings = model.encode(chunks)
```

### à¸à¸²à¸£à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸à¸±à¸š Vector Database

```
# à¹€à¸à¸´à¹ˆà¸¡à¹ƒà¸™ requirements_dataset.txt
# qdrant-client>=1.1.0

# à¹ƒà¸Šà¹‰à¹ƒà¸™ dataset_generator.py
from qdrant_client import QdrantClient

client = QdrantClient("localhost", port=6333)
client.upsert(collection_name="rag_chunks", points=embeddings)
```

## ğŸ¤ à¸à¸²à¸£à¸¡à¸µà¸ªà¹ˆà¸§à¸™à¸£à¹ˆà¸§à¸¡

1. Fork à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„
2. à¸ªà¸£à¹‰à¸²à¸‡ feature branch
3. Commit à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡
4. Push à¹„à¸›à¸¢à¸±à¸‡ branch
5. à¸ªà¸£à¹‰à¸²à¸‡ Pull Request

## ğŸ“„ License

MIT License - à¸”à¸¹à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¹ƒà¸™à¹„à¸Ÿà¸¥à¹Œ LICENSE

## ğŸ“ à¸à¸²à¸£à¸•à¸´à¸”à¸•à¹ˆà¸­

à¸«à¸²à¸à¸¡à¸µà¸„à¸³à¸–à¸²à¸¡à¸«à¸£à¸·à¸­à¸›à¸±à¸à¸«à¸² à¸à¸£à¸¸à¸“à¸²à¸ªà¸£à¹‰à¸²à¸‡ Issue à¹ƒà¸™ GitHub repository

